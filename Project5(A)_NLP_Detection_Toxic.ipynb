{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project5_NLP_Detection_Toxic.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Y2OUp3hR29W9","colab_type":"text"},"source":["#PROJECT NLP: PHÂN LOẠI COMMNET (TOXIC - NON TOXIC)\n","---\n","Xử lý ngôn ngữ tự nhiên (natural language processing - NLP) là một nhánh của trí tuệ nhân tạo tập trung vào các ứng dụng trên ngôn ngữ của con người. Trong trí tuệ nhân tạo thì xử lý ngôn ngữ tự nhiên là một trong những phần khó nhất vì nó liên quan đến việc phải hiểu ý nghĩa ngôn ngữ-công cụ hoàn hảo nhất của tư duy và giao tiếp. (wikipedia)\n","\n","\n","Tập dữ liệu bao gồm 56700 comment với 2 thuộc tính (class, tweet),\n","\n","\n","1.  Class cho biết comment này thuộc lớp nào:\n","    *   0 : Non Toxic\n","    *   1 : Toxic \n","2. Tweet tập hợp các commnet, dữ liệu này chưa được xử lý.\n","\n","![alt text](http://datajango.com/wp-content/uploads/2019/06/nlp_with_without_DL.png)\n","\n","\n","**CÁC VẤN ĐỀ GIẢI QUYẾT TRONG PROJECT:**\n","* Nghiên cứu các phương pháp tiền xử lý dữ liệu văn bản: Làm sạch dữ liệu (loại bỏ các nhiễu, chuyển chữ thường, địa chỉ email, link, dấu câu, số...) | Loại bỏ stopword, thực hiện chuẩn hóa từ (Stemming và Lemmatization)\n","* Nghiên cứu các phương pháp trích chọn đặc trưng văn bản (TF-IDF, Bag of Word) sử dụng cho mô hình học máy\n","* Sử dụng một số thuật toán học máy để phân lớp văn bản: Naive Bayes, SVM, KNN\n","* Nghiên cứu Spacy để thực hiện Word2vec\n","* Nghiên cứu mạng LSTM trong xử lý NLP để phân lớp văn bản\n","* Tìm hiểu thư viện ELI5 và Sử dụng thư viện này để minh họa trực quan kết quả\n","---\n","dangvannam|Department of Computer Science@2020\n"]},{"cell_type":"markdown","metadata":{"id":"lKK4HIas7F4w","colab_type":"text"},"source":["# I. TẢI TẬP DỮ LIỆU DATA_NLP VÀ QUAN SÁT TẬP DỮ LIỆU\n","---\n","Toàn bộ Tập dữ liệu thô lưu trữ trong file Data_NLP.csv trên google drive"]},{"cell_type":"code","metadata":{"id":"V09MKrjH6O6o","colab_type":"code","outputId":"357bfe3d-3bf8-48fe-aa76-33f387eaea62","executionInfo":{"status":"ok","timestamp":1585104360705,"user_tz":-420,"elapsed":27918,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhuAjjEz-tYvqqEOaxeOXVPZ5IK-hH05xHoWhkBbA=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":128}},"source":["#Thực hiện mount tới drive chứa file dữ liệu của Project\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KUwc65m76cUI","colab_type":"code","outputId":"b505a93b-cd72-427c-f6c1-47fc03a05c46","executionInfo":{"status":"ok","timestamp":1585104364514,"user_tz":-420,"elapsed":1521,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhuAjjEz-tYvqqEOaxeOXVPZ5IK-hH05xHoWhkBbA=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":217}},"source":["#Đọc file dữ liệu Data_NLP.csv vào biến data\n","import pandas as pd\n","path='/content/drive/My Drive/Colab Notebooks/10Project/Data5_NLP/Data_NLP.csv'\n","data = pd.read_csv(path)\n","\n","#Hiển thị 10 dòng dữ liệu đầu tiên của tập dữ liệu\n","print(data.head(10))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["   class                                              tweet\n","0      0  !!! RT @mayasolovely: As a woman you shouldn't...\n","1      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n","2      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n","3      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n","4      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n","5      1  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...\n","6      1  !!!!!!\"@__BrighterDays: I can not just sit up ...\n","7      1  !!!!&#8220;@selfiequeenbri: cause I'm tired of...\n","8      1  \" &amp; you might not get ya bitch back &amp; ...\n","9      1  \" @rhythmixx_ :hobbies include: fighting Maria...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fDT8NVvmiiLC","colab_type":"code","outputId":"be034029-2b2a-4a1f-94fe-e24a4fff4ac1","executionInfo":{"status":"ok","timestamp":1571197853323,"user_tz":-420,"elapsed":682,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":343}},"source":["#Hiển thị 10 dòng cuối cùng của data\n","data.tail(10)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>56690</th>\n","      <td>0</td>\n","      <td>@user love that your statements came from the ...</td>\n","    </tr>\n","    <tr>\n","      <th>56691</th>\n","      <td>0</td>\n","      <td>if dudes wana fuck eachother n get married, i ...</td>\n","    </tr>\n","    <tr>\n","      <th>56692</th>\n","      <td>0</td>\n","      <td>steak night at work means a night off training...</td>\n","    </tr>\n","    <tr>\n","      <th>56693</th>\n","      <td>0</td>\n","      <td>@user @user not a brown-noser?? you're practic...</td>\n","    </tr>\n","    <tr>\n","      <th>56694</th>\n","      <td>0</td>\n","      <td>.... because i choose to be.</td>\n","    </tr>\n","    <tr>\n","      <th>56695</th>\n","      <td>1</td>\n","      <td>i couldn't end #2016 without mentioning #trump...</td>\n","    </tr>\n","    <tr>\n","      <th>56696</th>\n","      <td>0</td>\n","      <td>#chateaubriand #stovells absolutely lovely #fo...</td>\n","    </tr>\n","    <tr>\n","      <th>56697</th>\n","      <td>0</td>\n","      <td>@user #frarou woohoo! #euro2016 kicks off..!</td>\n","    </tr>\n","    <tr>\n","      <th>56698</th>\n","      <td>0</td>\n","      <td>and here i thought @user  and i were having a ...</td>\n","    </tr>\n","    <tr>\n","      <th>56699</th>\n","      <td>0</td>\n","      <td>happy tuesday!! feeling fantastic today. looki...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       class                                              tweet\n","56690      0  @user love that your statements came from the ...\n","56691      0  if dudes wana fuck eachother n get married, i ...\n","56692      0  steak night at work means a night off training...\n","56693      0  @user @user not a brown-noser?? you're practic...\n","56694      0                      .... because i choose to be. \n","56695      1  i couldn't end #2016 without mentioning #trump...\n","56696      0  #chateaubriand #stovells absolutely lovely #fo...\n","56697      0     @user #frarou woohoo! #euro2016 kicks off..!  \n","56698      0  and here i thought @user  and i were having a ...\n","56699      0  happy tuesday!! feeling fantastic today. looki..."]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"9BZj5GlxhDR_","colab_type":"code","outputId":"0c8be86e-af21-4755-d1f1-d535a9880160","executionInfo":{"status":"ok","timestamp":1571198653911,"user_tz":-420,"elapsed":1107,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["#Kiểm tra dữ liệu null trong tập dữ liệu:\n","\n","print('Kiểm tra dữ liệu null trong tập dữ liệu:')\n","print(data.isnull().sum())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Kiểm tra dữ liệu null trong tập dữ liệu:\n","class    0\n","tweet    0\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Dr_oamhB7lKg","colab_type":"code","outputId":"4f4b29e5-3e95-44ba-b8af-75594a030164","executionInfo":{"status":"ok","timestamp":1571208997381,"user_tz":-420,"elapsed":1021,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":168}},"source":["#Quan sát tập dữ liệu:\n","print('Thông kê tập dữ liệu:')\n","print(data.count())\n","print('-----------------------------------')\n","print('Thông kê số lượng comment theo lớp:')\n","print(data['class'].value_counts())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Thông kê tập dữ liệu:\n","class    56700\n","tweet    56700\n","dtype: int64\n","-----------------------------------\n","Thông kê số lượng comment theo lớp:\n","0    33847\n","1    22853\n","Name: class, dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Fr3-HYPC7xpf","colab_type":"code","outputId":"70a4ffcd-05cf-4009-e530-d6e89597f036","executionInfo":{"status":"ok","timestamp":1571209004020,"user_tz":-420,"elapsed":993,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":282}},"source":["#Trực quan hóa tập dữ liệu đầu vào\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","sns.barplot(['Non Toxic', 'Toxic'], data['class'].map({0:\"Non Toxic\", 1: \"Toxic\"}).value_counts(), alpha=0.8,palette=\"vlag\")\n","plt.title('Thống kê số lượng comment trong tập dữ liệu ')\n","plt.grid=True"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAZUAAAEJCAYAAABc/7oDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzKwYBxUzMyvGQcXMzIpxUDEzs2L+P13C2Wt3RcqVAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"GWEMPKiQiqxY","colab_type":"code","outputId":"45758aa5-b4f4-43f4-f195-98696da1141f","executionInfo":{"status":"ok","timestamp":1571198769345,"user_tz":-420,"elapsed":1163,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":77}},"source":["data.loc[[56000],['tweet']]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>56000</th>\n","      <td>fabric doll handmade stuffed doll #tilda #doll...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   tweet\n","56000  fabric doll handmade stuffed doll #tilda #doll..."]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"UGmKfPWf8yRu","colab_type":"text"},"source":["# II.TIỀN XỬ LÝ DỮ LIỆU\n","---\n","\n","Sử dụng thư viện Natural Language Tool Kit (NLTK) thực hiện xử lý các comment\n","\n","NLTK là một bộ công cụ dành riêng cho Natural Language Processing và được tích hợp vào Python. Nó đang ngày càng hoàn thiện và tích hợp các công cụ mới bởi hàng nghìn lập trình viên và cộng tác viên trên khắp thế giới. NLTK bao gồm những thư viện hàm, các công cụ phân tích, các corpus, wordnet, …giúp đơn giản hóa, tiết kiệm thời gian và công sức cho các lập trình viên. Python kết hợp với NLTK là bộ công cụ hữu hiệu và mạnh mẽ nhất dành cho Natural Language Processing.\n","\n","http://www.nltk.org/\n"]},{"cell_type":"code","metadata":{"id":"QA_5uA_K88yQ","colab_type":"code","outputId":"719c4341-6a26-4bbd-8c5b-191872360e75","executionInfo":{"status":"ok","timestamp":1571363732270,"user_tz":-420,"elapsed":2639,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":151}},"source":["#Khai báo sử dụng thư viện NLTK\n","\n","import nltk\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"I2f4esC0zAce","colab_type":"text"},"source":["###2.1) Làm sạch dữ liệu\n","----\n","Mục đích bước này là loại bỏ noise trong data của bạn. Đa phần noise là các thẻ HTML, JavaScript, và đương nhiên nếu cứ để noise để tiến hành xử lý sẽ dẫn đến kết quả xử lý không tốt.\n","\n","Thư viện re — Regular expression operations: thao tác với biểu thức chính quy\n","\n","https://regex101.com/"]},{"cell_type":"code","metadata":{"id":"wdZSsvTX_-K8","colab_type":"code","colab":{}},"source":["#Thư viện re — Regular expression operations: thao tác với biểu thức chính quy\n","import re\n","\n","\n","#hàm decontracted thực hiện chuyển đổi các phần viết tắt thành câu đầy đủ\n","def decontracted(st):\n","    # specific\n","    st = re.sub(r\"won\\'t\", \"will not\", st)\n","    st = re.sub(r\"can\\'t\", \"can not\", st)\n","    # general\n","    st = re.sub(r\"n\\'t\", \" not\", st)\n","    st = re.sub(r\"\\'re\", \" are\", st)\n","    st = re.sub(r\"\\'s\", \" is\", st)\n","    st = re.sub(r\"\\'d\", \" would\", st)\n","    st = re.sub(r\"\\'ll\", \" will\", st)\n","    st = re.sub(r\"\\'ve\", \" have\", st)\n","    st = re.sub(r\"\\'m\", \" am\", st)\n","    return st\n","\n","#hàm clear_link thực hiện loại bỏ liên kết (link), địa chỉ email trong câu\n","def clear_link(st):\n","    #Remove links/email\n","    word = re.sub(r'((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*', \n","                '', st, flags=re.MULTILINE)\n","    word = re.sub(r'(@[^\\s]*)', \"\", word)\n","    #word = re.sub('[\\W]', ' ', st)\n","    return word\n","\n","#Hàm clear_punctuation thực hiện loai bỏ các dấu câu, ký tự đặc biệt trong chuỗi\n","def clear_punctuation(st):\n","    word = re.sub(r'[^\\w\\s]', '',st)\n","    return word\n","\n","#Hàm clear_special loại bỏ các ký tự chỉ để lại các ký tự chữ a-z, A-Z\n","def clear_special(st):\n","    word = re.sub('[^a-zA-Z]', ' ', st)\n","    return word\n","\n","\n","#Hàm clear_noise kết hợp sử dụng các hàm ở trên để xử lý chuỗi\n","def clear_noise(word):\n","    word = word.lower()         # chuyển toàn bộ sang chữ thường để xử lý\n","    word = decontracted(word)\n","    word = clear_link(word)\n","    word = clear_punctuation(word)\n","    word = clear_special(word)\n","    return word"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FN33R8CIDWvO","colab_type":"code","outputId":"389cb7ec-c53e-4a25-ebb3-6b0beb563b34","executionInfo":{"status":"ok","timestamp":1571208525030,"user_tz":-420,"elapsed":961,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["#Kiểm tra việc xử lý với các hàm đã xây dựng\n","\n","text = \"\"\"I won't give up @nam to learn English 123; dangnam1985@gmail.com - http://dantri.com.vn, i am going to visited Ha Long bay (^.^); he had gone aboard for 2 years\"\"\"\n","print(text)\n","\n","#text1 = decontracted(text)\n","#text1 =clear_link(text)\n","#text1 = clear_punctuation(text)\n","#text1 = clear_special(text)\n","text1 = clear_noise(text)\n","\n","print(text1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["I won't give up @nam to learn English 123; dangnam1985@gmail.com - http://dantri.com.vn, i am going to visited Ha Long bay (^.^); he had gone aboard for 2 years\n","i will not give up  to learn english        i am going to visited ha long bay  he had gone aboard for   years\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SDwf8ElpbloG","colab_type":"text"},"source":["###2.2) Loại bỏ stopword\n","---\n","\n","StopWords là những từ xuất hiện nhiều trong ngôn ngữ tự nhiên, tuy nhiên lại không mang nhiều ý nghĩa. Ở tiếng việt StopWords là những từ như: để, này, kia... Tiếng anh là những từ như: is, that, this... Tham khảo thêm tại danh sách stopwords trong tiếng việt\n","\n","Có rất nhiều cách để loại bỏ StopWords nhưng có 2 cách chính là:\n","\n","* Dùng từ điển\n","\n","* Dựa theo tần suất xuất hiện của từ"]},{"cell_type":"code","metadata":{"id":"Ji4XxzOipK1a","colab_type":"code","outputId":"826a51f7-6dfc-477c-dfbc-bb26d17e2d46","executionInfo":{"status":"ok","timestamp":1571363740300,"user_tz":-420,"elapsed":686,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["#stopwords là những từ xuất hiện nhiều trong văn bản, nhưng ko có ý nghĩa \n","#Load danh sách Stopword trong tiếng anh\n","\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","stop = stopwords.words('english')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vMavhhICna57","colab_type":"code","outputId":"f0c70d31-b99c-4b96-b207-df404e0aa380","executionInfo":{"status":"ok","timestamp":1571208047420,"user_tz":-420,"elapsed":1101,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["#Hiển thị danh sách các stopwords trong tiếng anh\n","print(stop)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"427fDeFnnqMI","colab_type":"code","colab":{}},"source":["#hàm clear_stopwords loai bỏ các từ stopword trong câu\n","def clear_stopwords(st):\n","    word = \" \".join(st for st in st.split() if st not in stop)\n","    return word"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SWJrRRWMoUCl","colab_type":"code","outputId":"31733e50-eed7-4a92-cccf-7f3a73745819","executionInfo":{"status":"ok","timestamp":1571208544330,"user_tz":-420,"elapsed":1237,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["print(text1)\n","text2 = clear_stopwords(text1)\n","print(text2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["i will not give up  to learn english        i am going to visited ha long bay  he had gone aboard for   years\n","give learn english going visited ha long bay gone aboard years\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y_ue2I8nh1VH","colab_type":"text"},"source":["###2.3) Chuẩn hóa từ (Stemming và Lemmatization)\n","---\n","Trong quá trình xử lý ngôn ngữ tự nhiên, chúng ta sẽ có nhu cầu so sánh các từ (token) với nhau. Việc so sánh này tưởng chừng như đơn giản là lấy 2 chuỗi ký tự và dùng phép “==” để kiểm tra, nhưng thực tế thì không phải là như vậy. Đối với một số ngôn ngữ, tiêu biểu là tiếng Anh, mỗi từ có thể có nhiều biến thể khác nhau. Điều này làm cho việc so sánh giữa các từ là không thể mặc dù về mặc ý nghĩa cơ bản là như nhau. Ví dụ các từ “walks“, “walking“, “walked” đều là các biến thể của từ “walk” và đều mang ý nghĩa là “đi bộ”. Vậy làm sao để so sánh các từ như thế với nhau? Lemmatization và Stemming chính là 2 kỹ thuật thường được dùng cho việc này.\n","\n","Stemming là kỹ thuật dùng để biến đổi 1 từ về dạng gốc (được gọi là stem hoặc root form) bằng cách cực kỳ đơn giản là loại bỏ 1 số ký tự nằm ở cuối từ mà nó nghĩ rằng là biến thể của từ. Ví dụ như chúng ta thấy các từ như walked, walking, walks chỉ khác nhau là ở những ký tự cuối cùng, bằng cách bỏ đi các hậu tố –ed, –ing hoặc –s, chúng ta sẽ được từ nguyên gốc là walk. Người ta gọi các bộ xử lý stemming là Stemmer.\n","\n","Bởi vì nguyên tắc hoạt động của stemmer rất là đơn giản như vậy cho nên tốc độ xử lý của nó rất là nhanh, và kết quả stem đôi khi không được như chúng ta mong muốn. Chẳng hạn như từ goes sẽ được stem thành từ goe (bỏ chữ s cuối từ) trong khi đó stem của từ go vẫn là go, kết quả là 2 từ “goes” và “go” sau khi được stem thì vẫn không giống nhau. Một nhược điểm khác là nếu các từ dạng bất quy tắt như went hay spoke thì stemmer sẽ không thể đưa các từ này về dạng gốc là go hay speak.\n","\n","Tuy có các nhược điểm như trên nhưng trong thực tế Stemming vẫn được sử dụng khá phổ biến trong NLP vì nó có tốc độ xử lý nhanh và kết quả cuối cùng nhìn chung không hề tệ khi so với Lemmatization."]},{"cell_type":"code","metadata":{"id":"4a7qdK1KjHpA","colab_type":"code","colab":{}},"source":["from nltk.stem import WordNetLemmatizer\n","wn = WordNetLemmatizer()\n","import string\n","my_sw = ['rt', 'ht', 'fb', 'amp', 'gt']\n","\n","def black_txt(token):\n","  if token == 'u':\n","    token = 'you'\n","  return  token not in stop and token not in list(string.punctuation) and token not in my_sw\n","\n","\n","def fun_stemlem(word):\n","  list_word_clean = []\n","  for w1 in word.split(\" \"):\n","    if  black_txt(w1.lower()):\n","      word_lemma =  wn.lemmatize(w1,  pos=\"v\")\n","      list_word_clean.append(word_lemma)\n","\n","  #Cleaning, lowering and remove whitespaces\n","  word = \" \".join(list_word_clean)\n","  return word "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f3spT140lfz-","colab_type":"code","outputId":"a036eef2-fcad-4139-856e-921f8234a925","executionInfo":{"status":"ok","timestamp":1571208302456,"user_tz":-420,"elapsed":998,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["st1 = data.iloc[2000]['tweet']\n","st1"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'&amp; my sister is really going to fucken deny it but yet sprays the room with febreeze , like really bitch why are you going to deny it'"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"ozS-E8nojxD2","colab_type":"code","outputId":"9816f6c0-fa92-45f4-f5ad-0467ff37303b","executionInfo":{"status":"ok","timestamp":1571208383668,"user_tz":-420,"elapsed":2605,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["sta = clear_noise(st1)\n","stb = clear_stopwords(sta)\n","stc = fun_stemlem(stb)\n","print(stc)   "],"execution_count":0,"outputs":[{"output_type":"stream","text":["sister really go fucken deny yet spray room febreeze like really bitch go deny\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0emrSyAVnRXL","colab_type":"text"},"source":["### 2.4) Tiền Xử lý dữ liệu với các hàm đã xây dựng\n","---\n"]},{"cell_type":"code","metadata":{"id":"suNXjcecnYuY","colab_type":"code","colab":{}},"source":["def prepare_data(word):\n","    word = clear_noise(word)        #Loại bỏ nhiễu trong các comment\n","    word = clear_stopwords(word)    #Loại bỏ stopword trong các comment\n","    word = fun_stemlem(word)        #Chuẩn hóa comment\n","    return word\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NzHiqrubUiqJ","colab_type":"code","outputId":"a49145b7-5f79-4e4d-db62-5d7929985ebd","executionInfo":{"status":"ok","timestamp":1571208622273,"user_tz":-420,"elapsed":2381,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["print('Raw text:',text)\n","print('New Text:',prepare_data(text))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Raw text: I won't give up @nam to learn English 123; dangnam1985@gmail.com - http://dantri.com.vn, i am going to visited Ha Long bay (^.^); he had gone aboard for 2 years\n","New Text: give learn english go visit ha long bay go aboard years\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V5GNdQJXnw9u","colab_type":"code","outputId":"c707d9ba-a252-4621-e024-55854519c337","executionInfo":{"status":"ok","timestamp":1571209067589,"user_tz":-420,"elapsed":989,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":709}},"source":["#Hiển thị danh sách các từ trước và sau khi chuẩn hóa để test\n","for idx in data[30090:30100].index:\n","  print(idx, '\\n', data.iloc[idx]['tweet'],'\\n',prepare_data(data.iloc[idx]['tweet']))\n","  print(\"************\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["30090 \n"," i'm so #loyal. sucks when it's not reciprocated. #bummed   \n"," loyal suck reciprocate bum\n","************\n","30091 \n","  @user plz don't u dare forget @user majority @user vote against #gunsense bills 4 @user long $$! @user @user  \n"," plz dare forget majority vote gunsense bill long\n","************\n","30092 \n"," beð ð@user @user @user @user @user @user @user @user @user @user \n"," \n","************\n","30093 \n"," âhappiness often sneaks in through a door you didn't know you left open.â john barrymore #live #life #happiness   #open \n"," happiness often sneak door know leave open john barrymore live life happiness open\n","************\n","30094 \n"," its the hae tym u knw that life is sho no matter how old u r live life to the fullest! #self-acceptance  #life   #knowyourboundaries \n"," hae tym knw life sho matter old r live life fullest selfacceptance life knowyourboundaries\n","************\n","30095 \n","  â #australia unemployment rate s.a. in line with expectations (5.7%) in may   #blog #silver #gold #forex \n"," australia unemployment rate sa line expectations may blog silver gold forex\n","************\n","30096 \n","  @user hello!!! #fashion #fashionillustration #design #fashiondesign #a #draw #drawing   #funâ¦  \n"," hello fashion fashionillustration design fashiondesign draw draw fun\n","************\n","30097 \n"," j.c penney employee holds customer in headlock   wow and they havent responded! #corporatebs  #boycottjcpenney \n"," jc penney employee hold customer headlock wow havent respond corporatebs boycottjcpenney\n","************\n","30098 \n"," happy friday! #schnauzer #schnauzerlove #smile   #love #friday  \n"," happy friday schnauzer schnauzerlove smile love friday\n","************\n","30099 \n"," threats from terrorists are becoming real    \n"," threats terrorists become real\n","************\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d8fCL6WuCRKE","colab_type":"code","colab":{}},"source":["#LÀM SẠCH TOÀN BỘ TẬP DỮ LIỆU\n","#----------------------------------------------------------------------------------------------------------\n","#Tạo dataframe data_new, bổ sung thêm field: tweet_ok là comment đã được tiền xử lý dữ liệu tương ứng\n","data_new = data.copy()\n","data_new['tweet_ok'] = data['tweet'].apply(lambda x: prepare_data(x))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NMM8hRwyCWjd","colab_type":"code","outputId":"36cf3bcc-862e-4442-a5d0-63e7d4e4b16f","executionInfo":{"status":"ok","timestamp":1571208761969,"user_tz":-420,"elapsed":1347,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":343}},"source":["data_new.head(10)\n","#data.head(10)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>tweet</th>\n","      <th>tweet_ok</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n","      <td>woman complain clean house man always take trash</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n","      <td>boy dats dwn bad cuffin dat hoe st place</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n","      <td>dawg ever fuck bitch start cry confuse shit</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n","      <td>look like tranny</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n","      <td>shit hear might true might faker bitch tell ya</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>!!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...</td>\n","      <td>shit blow faithful somebody still fuck hoe</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1</td>\n","      <td>!!!!!!\"@__BrighterDays: I can not just sit up ...</td>\n","      <td>sit hate another bitch get much shit go</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>!!!!&amp;#8220;@selfiequeenbri: cause I'm tired of...</td>\n","      <td>cause tire big bitch come us skinny girls</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1</td>\n","      <td>\" &amp;amp; you might not get ya bitch back &amp;amp; ...</td>\n","      <td>might get ya bitch back thats</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1</td>\n","      <td>\" @rhythmixx_ :hobbies include: fighting Maria...</td>\n","      <td>hobbies include fight mariam bitch</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   class  ...                                          tweet_ok\n","0      0  ...  woman complain clean house man always take trash\n","1      1  ...          boy dats dwn bad cuffin dat hoe st place\n","2      1  ...       dawg ever fuck bitch start cry confuse shit\n","3      1  ...                                  look like tranny\n","4      1  ...    shit hear might true might faker bitch tell ya\n","5      1  ...        shit blow faithful somebody still fuck hoe\n","6      1  ...           sit hate another bitch get much shit go\n","7      1  ...         cause tire big bitch come us skinny girls\n","8      1  ...                     might get ya bitch back thats\n","9      1  ...                hobbies include fight mariam bitch\n","\n","[10 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"V755mg30h9OM","colab_type":"text"},"source":["### 2.6) Lưu kết quả đã xử lý ra file\n","---\n","\n","Sau khi tiền xử lý dữ liệu, có một số comment bị xóa toàn bộ các noise, trở thành các comment rỗng.\n","Thực hiện loại bỏ các Comment này ra khỏi tập dữ liệu."]},{"cell_type":"code","metadata":{"id":"FpAR70bgE6gE","colab_type":"code","outputId":"be9e096c-fb15-4367-c1b2-a7bfc5deaabb","executionInfo":{"status":"ok","timestamp":1571209139794,"user_tz":-420,"elapsed":877,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":343}},"source":["data_finish = data_new[['class','tweet_ok']]\n","data_finish.head(10)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>tweet_ok</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>woman complain clean house man always take trash</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>boy dats dwn bad cuffin dat hoe st place</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>dawg ever fuck bitch start cry confuse shit</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>look like tranny</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>shit hear might true might faker bitch tell ya</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>shit blow faithful somebody still fuck hoe</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1</td>\n","      <td>sit hate another bitch get much shit go</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>cause tire big bitch come us skinny girls</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1</td>\n","      <td>might get ya bitch back thats</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1</td>\n","      <td>hobbies include fight mariam bitch</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   class                                          tweet_ok\n","0      0  woman complain clean house man always take trash\n","1      1          boy dats dwn bad cuffin dat hoe st place\n","2      1       dawg ever fuck bitch start cry confuse shit\n","3      1                                  look like tranny\n","4      1    shit hear might true might faker bitch tell ya\n","5      1        shit blow faithful somebody still fuck hoe\n","6      1           sit hate another bitch get much shit go\n","7      1         cause tire big bitch come us skinny girls\n","8      1                     might get ya bitch back thats\n","9      1                hobbies include fight mariam bitch"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"pOxa7dq7h66W","colab_type":"code","outputId":"55911269-c8a8-47e0-ee8c-439a279f167a","executionInfo":{"status":"ok","timestamp":1571209153913,"user_tz":-420,"elapsed":1030,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":168}},"source":["#Ví dụ: Trường hợp sau khi tiền xử lý dữ liệu, còn lại chuỗi rỗng\n","print(data_new.iloc[30092])\n","print('---------------------------------')\n","print(data_new.iloc[32005])\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["class                                                       0\n","tweet       beð ð@user @user @user @user @user @user...\n","tweet_ok                                                     \n","Name: 30092, dtype: object\n","---------------------------------\n","class                             0\n","tweet       be   with who you are! \n","tweet_ok                           \n","Name: 32005, dtype: object\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4qxgrm3JFqiz","colab_type":"code","colab":{}},"source":["#Lưu kết quả sau khi đã xử lý ra file .csv\n","#File data_finish.csv chỉ lưu trữ 2 thuộc tính: class - tweet_ok (đã xử lý)\n","data_finish.to_csv('data_finish.csv',index=None, header=True)\n","\n","\n","#File data_all.csv Lưu trữ 3 thuộc tính: class - tweet (gốc) - tweet_ok (đã xử lý)\n","data_new.to_csv('data_all.csv',index=None, header=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hIMNlHV2X4Mk","colab_type":"text"},"source":["# III) SỬ DỤNG MÔ HÌNH HỌC MÁY TRONG PHÂN LỚP VĂN BẢN\n","---\n"]},{"cell_type":"markdown","metadata":{"id":"fZVO8i-IPmT3","colab_type":"text"},"source":["## III.1) Word Embedding\n","---\n","Khi huấn luyện mô hình máy học để xử lý ngôn ngữ tự nhiên, thì chắc chắn dữ liệu bạn có ở dạng chữ viết, sự thật là bạn không thể đem trực tiếp dữ liệu chữ viết thô vào để huấn luyện mô hình máy học ngay được, bởi vì các mô hình máy học chỉ làm việc được trên những con số, hay chính xác hơn là tính toán trên các ma trận, véc-tơ số.\n","\n","Điều này dẫn đến việc bạn phải nghĩ cách làm thế nào đó để chuyển dữ liệu chữ viết thô thành dữ liệu số thực, sau đó mới có thể đưa dữ liệu số thực này vào các mô hình học được, có rất nhiều kĩ thuật để làm việc này và gọi chung chúng là kĩ thuật Embedding.\n","\n","Đó chỉ mới là ý tưởng của kĩ thuật Embedding, còn việc chuyển từ không gian này sang một không gian vec-tơ khác bạn không thể làm tùy tiện được mà phải đảm bảo:\n","\n","* Không gian véc-tơ mới (hay véc-tơ số thực) phải thể hiện được bản chất của tập dữ liệu ban đầu (dữ liệu chữ viết).\n","* Cực tiểu hóa lượng mất mát thông tin xảy ra khi bạn chuyển sang không gian mới.\n","\n","Một số kĩ thuật Embedding được sử dụng phổ biến như mạng Neural Network, PCA (Principal Component Analysis) gọi là kĩ thuật phân tích thành phần chính, TF-IDF, Bag of Word, Encoder-Decoder sử dụng trong RNN (Recurrent Neural Network) hoặc LSTM (Long-Short Term Memory), ...v.v.\n","\n","Một số thư viện sử dụng kĩ thuật Embedding như sklearn, Word2vec, FastText, ...v.v.\n","\n","**Word Embedding** là tên gọi chung của các mô hình ngôn ngữ và các phương pháp học theo đặc trưng trong Xử lý ngôn ngữ tự nhiên(NLP), ở đó các từ hoặc cụm từ được ánh xạ sang các vector số (thường là số thực). Đây là một công cụ đóng vai trò quan trọng đối với hầu hết các thuật toán, kiến trúc Machine Learning, Deep Learning trong việc xử lý Input ở dạng text, do chúng chỉ có thể hiểu được Input ở dạng là số, từ đó mới thực hiện các công việc phân loại, hồi quy,vv…\n","\n","Word Embedding được phân chủ yếu thành 2 loại:\n","\n","* Frequency-based embedding.\n","* Prediction-based embedding."]},{"cell_type":"markdown","metadata":{"id":"LiXHTmgwabs0","colab_type":"text"},"source":["### 3.1) Chuẩn bị tập dữ liệu cho việc trích chọn đặc trưng"]},{"cell_type":"markdown","metadata":{"id":"gW6npz32n7Xj","colab_type":"text"},"source":["#### a) Tải tập dữ liệu đã xử lý\n","---\n","Thực hiện tải tập dữ liệu data_finish.csv đã được xử lý ở trên để thực hiện vector hóa."]},{"cell_type":"code","metadata":{"id":"hnqhVSMYQYxf","colab_type":"code","outputId":"aadd83f0-e651-48f8-abdb-18ab7e9a692c","executionInfo":{"status":"ok","timestamp":1571209199431,"user_tz":-420,"elapsed":1357,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":380}},"source":["#Tải file dữ liệu sau khi đã tiền xử lý\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import pandas as pd\n","path='/content/drive/My Drive/Colab Notebooks/10Project/Data_tweet/data_finish.csv'\n","#data_finish = pd.read_csv(path,encoding ='latin1')\n","data_finish = pd.read_csv(path)\n","data_finish.head(10)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>tweet_ok</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>woman complain clean house man always take trash</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>boy dats dwn bad cuffin dat hoe st place</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>dawg ever fuck bitch start cry confuse shit</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>look like tranny</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>shit hear might true might faker bitch tell ya</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>shit blow faithful somebody still fuck hoe</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1</td>\n","      <td>sit hate another bitch get much shit go</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>cause tire big bitch come us skinny girls</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1</td>\n","      <td>might get ya bitch back thats</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1</td>\n","      <td>hobbies include fight mariam bitch</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   class                                          tweet_ok\n","0      0  woman complain clean house man always take trash\n","1      1          boy dats dwn bad cuffin dat hoe st place\n","2      1       dawg ever fuck bitch start cry confuse shit\n","3      1                                  look like tranny\n","4      1    shit hear might true might faker bitch tell ya\n","5      1        shit blow faithful somebody still fuck hoe\n","6      1           sit hate another bitch get much shit go\n","7      1         cause tire big bitch come us skinny girls\n","8      1                     might get ya bitch back thats\n","9      1                hobbies include fight mariam bitch"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"markdown","metadata":{"id":"RNb9my5c3SLU","colab_type":"text"},"source":["#### b) Loại bỏ một số dữ liệu bị rỗng sau khi tiền xử lý\n","---\n","Sau khi thực hiện việc làm sạch dữ liệu, có một số dòng dữ liệu bị rỗng, cần phải loại bỏ các dòng dữ liệu này trước khi thực hiện chuyển về dạng số."]},{"cell_type":"code","metadata":{"id":"kw3gpaCIpjVu","colab_type":"code","outputId":"b15af311-51a5-478f-cc9a-b9958f0a784f","executionInfo":{"status":"ok","timestamp":1571209597215,"user_tz":-420,"elapsed":930,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["#Thống kê số row null trong tập dữ liệu:\n","data_finish.isnull().sum()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["class        0\n","tweet_ok    43\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"id":"OVHiBiT13p1x","colab_type":"code","outputId":"9591c659-f393-47f0-c9be-754a3b851c49","executionInfo":{"status":"ok","timestamp":1571209610698,"user_tz":-420,"elapsed":1474,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"source":["data_finish.info()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 56700 entries, 0 to 56699\n","Data columns (total 2 columns):\n","class       56700 non-null int64\n","tweet_ok    56657 non-null object\n","dtypes: int64(1), object(1)\n","memory usage: 886.0+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cGxe1iM0klNz","colab_type":"code","outputId":"bbea8eb6-4d79-4214-d8ae-1ab5f2d1134e","executionInfo":{"status":"ok","timestamp":1571209215254,"user_tz":-420,"elapsed":800,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#Liệt kê chi tiết các row null\n","data_finish[pd.isnull(data_finish).any(axis=1)]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>tweet_ok</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2637</th>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4828</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>6098</th>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>6613</th>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>25441</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>26744</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>28134</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>28765</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>29194</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>29582</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>29811</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>30018</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>30092</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>32005</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>32722</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>33817</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>35244</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>35585</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>36369</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>36432</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>36635</th>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>36665</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>37821</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>38070</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>38631</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>38645</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>40217</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>40277</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>40865</th>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>41033</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>41103</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>42815</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>42963</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>43868</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>45044</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>46753</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>47492</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>48297</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>49450</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>50412</th>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>53296</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>54586</th>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>56564</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       class tweet_ok\n","2637       1      NaN\n","4828       0      NaN\n","6098       1      NaN\n","6613       1      NaN\n","25441      0      NaN\n","26744      0      NaN\n","28134      0      NaN\n","28765      0      NaN\n","29194      0      NaN\n","29582      0      NaN\n","29811      0      NaN\n","30018      0      NaN\n","30092      0      NaN\n","32005      0      NaN\n","32722      0      NaN\n","33817      0      NaN\n","35244      0      NaN\n","35585      0      NaN\n","36369      0      NaN\n","36432      0      NaN\n","36635      1      NaN\n","36665      0      NaN\n","37821      0      NaN\n","38070      0      NaN\n","38631      0      NaN\n","38645      0      NaN\n","40217      0      NaN\n","40277      0      NaN\n","40865      1      NaN\n","41033      0      NaN\n","41103      0      NaN\n","42815      0      NaN\n","42963      0      NaN\n","43868      0      NaN\n","45044      0      NaN\n","46753      0      NaN\n","47492      0      NaN\n","48297      0      NaN\n","49450      0      NaN\n","50412      1      NaN\n","53296      0      NaN\n","54586      1      NaN\n","56564      0      NaN"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"I3MEPBPLmQtO","colab_type":"code","colab":{}},"source":["#Thực hiện xóa tất cả các row có phần tử NaN\n","data_finish = data_finish.dropna()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kbrYCD0DZM-u","colab_type":"code","colab":{}},"source":["#Lưu dữ liệu sau khi đã loại bỏ các dòng trống\n","#File data_finish_no_null.csv Lưu trữ 2 thuộc tính: class - tweet_ok\n","data_finish.to_csv('data_finish_no_null.csv',index=None, header=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ueATfcXLno68","colab_type":"text"},"source":["#### c) Tách thành tập Train - Test\n","---\n"]},{"cell_type":"code","metadata":{"id":"y2TG_rPcZZyg","colab_type":"code","outputId":"b58cba72-9522-45f7-a736-8f8d8431db2d","executionInfo":{"status":"ok","timestamp":1571209800020,"user_tz":-420,"elapsed":1507,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":380}},"source":["#------------NẾU CẦN ----------------------------------------------------\n","#Đọc lại tập dữ liệu sau khi đã loại bỏ dòng rỗng:\n","#Tải file dữ liệu sau khi đã tiền xử lý\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import pandas as pd\n","path='/content/drive/My Drive/Colab Notebooks/10Project/Data_tweet/data_finish_no_null.csv'\n","data_NLP = pd.read_csv(path)\n","data_NLP.head(10)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>tweet_ok</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>woman complain clean house man always take trash</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>boy dats dwn bad cuffin dat hoe st place</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>dawg ever fuck bitch start cry confuse shit</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>look like tranny</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>shit hear might true might faker bitch tell ya</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>shit blow faithful somebody still fuck hoe</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1</td>\n","      <td>sit hate another bitch get much shit go</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>cause tire big bitch come us skinny girls</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1</td>\n","      <td>might get ya bitch back thats</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1</td>\n","      <td>hobbies include fight mariam bitch</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   class                                          tweet_ok\n","0      0  woman complain clean house man always take trash\n","1      1          boy dats dwn bad cuffin dat hoe st place\n","2      1       dawg ever fuck bitch start cry confuse shit\n","3      1                                  look like tranny\n","4      1    shit hear might true might faker bitch tell ya\n","5      1        shit blow faithful somebody still fuck hoe\n","6      1           sit hate another bitch get much shit go\n","7      1         cause tire big bitch come us skinny girls\n","8      1                     might get ya bitch back thats\n","9      1                hobbies include fight mariam bitch"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"CDhCUeXUJO7C","colab_type":"code","outputId":"be5c35a1-78be-412a-a921-071a361ecc37","executionInfo":{"status":"ok","timestamp":1571210664549,"user_tz":-420,"elapsed":855,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["#THỰC HIỆN TÁCH TẬP DỮ LIỆU THÀNH TẬP TRAIN VÀ TEST\n","from sklearn import model_selection\n","#Tách tập dữ liệu thành Train - Test (tỷ lệ: 0.8 - 0.2)\n","train_x,test_x,train_y,test_y=model_selection.train_test_split(data_NLP['tweet_ok'],data_NLP['class'],test_size=0.2)\n","\n","print('Tập Train (80%): ', train_x.shape)\n","print('Tập Test (20%): ', test_x.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Tập Train (80%):  (45325,)\n","Tập Test (20%):  (11332,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uvuIS6qQJVRZ","colab_type":"text"},"source":["### 3.2) Tính đặc trưng theo TF-IDF\n","----\n","Viết tắt của thuật ngữ tiếng Anh term frequency – inverse document frequency,tf-idf là trọng số của một từ trong văn bản thu được qua thống kê thể hiện mức độ quan trọng của từ này trong một văn bản, mà bản thân văn bản đang xét nằm trong một tập hợp các văn bản.\n","\n","**Các tính trọng số TF-IDF:**\n","* Tf- term frequency : dùng để ước lượng tần xuất xuất hiện của từ trong văn bản. Tuy nhiên với mỗi văn bản thì có độ dài khác nhau, vì thế số lần xuất hiện của từ có thể nhiều hơn . Vì vậy số lần xuất hiện của từ sẽ được chia độ dài của văn bản (tổng số từ trong văn bản đó)\n","\n","    * TF(t, d) = (số lần từ t xuất hiện trong văn bản d) / (tổng số từ trong văn bản d)\n","\n","* IDF- Inverse Document Frequency: dùng để ước lượng mức độ quan trọng của từ đó như thế nào . Khi tính tần số xuất hiện tf thì các từ đều được coi là quan trọng như nhau. Tuy nhiên có một số từ thường được được sử dụng nhiều nhưng không quan trọng để thể hiện ý nghĩa của đoạn văn. Vì vậy ta cần giảm đi mức độ quan trọng của những từ đó bằng cách sử dụng IDF :\n","\n","    * IDF(t, D) = log_e( Tổng số văn bản trong tập mẫu D/ Số văn bản có chứa từ t )\n"]},{"cell_type":"code","metadata":{"id":"Xu-08BJvKDn5","colab_type":"code","outputId":"082f1412-942d-4532-d3d4-0c0893c9c404","executionInfo":{"status":"ok","timestamp":1571210679188,"user_tz":-420,"elapsed":2190,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["# Tính TF-IDF cho tập dữ liệu\n","import numpy as np\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import sklearn.feature_extraction.text as text\n","\n","#Convert a collection of raw documents to a matrix of TF-IDF features.\n","\n","vector = TfidfVectorizer(analyzer='word', max_features=15000, stop_words = 'english')\n","\n","vector.fit(data_NLP['tweet_ok'])\n","xtrain_tfidf = vector.transform(train_x)\n","xtest_tfidf = vector.transform(test_x)\n","xtrain_tfidf.data\n","     "],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.42380266, 0.47214547, 0.2228723 , ..., 0.4050343 , 0.33295781,\n","       1.        ])"]},"metadata":{"tags":[]},"execution_count":73}]},{"cell_type":"code","metadata":{"id":"lFXbvNWJKEmO","colab_type":"code","outputId":"e1bfeb05-fee7-49c2-816b-8723af79ff1c","executionInfo":{"status":"ok","timestamp":1571210684504,"user_tz":-420,"elapsed":944,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["print(xtrain_tfidf[100].data)\n","print(xtrain_tfidf.data.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0.6268216  0.28654892 0.36342687 0.6268216 ]\n","(264965,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"odES_Y4wbZYg","colab_type":"text"},"source":["### 3.3) Đặc trưng Bag of Word\n","---"]},{"cell_type":"code","metadata":{"id":"0kQv6ZrxbgFY","colab_type":"code","colab":{}},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","#Count vectorizer for bag of words\n","cv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))\n","#transformed train reviews\n","xtrain_bow=cv.fit_transform(train_x)\n","#transformed test reviews\n","xtest_bow=cv.transform(test_x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o4qjhbhnbzYv","colab_type":"code","outputId":"f11472f7-fc61-4749-bc45-717a6eb28862","executionInfo":{"status":"ok","timestamp":1571210356026,"user_tz":-420,"elapsed":869,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["print('BOW_cv_train:',xtrain_bow.shape)\n","print('BOW_cv_test:',xtest_bow.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["BOW_cv_train: (45325, 404448)\n","BOW_cv_test: (11332, 404448)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nDw-xeMxb5Ul","colab_type":"code","outputId":"76615e71-8997-4ad5-9718-6731507776e7","executionInfo":{"status":"ok","timestamp":1571210378423,"user_tz":-420,"elapsed":850,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":185}},"source":["for i in range(10000,10010):\n","    print(xtrain_bow[i].data)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[1 1 1]\n","[1 1 1 1 1 1]\n","[1 1 1 1 1 1 1 1]\n","[1 1 1]\n","[1 1]\n","[]\n","[1 1 1 1 1 1 1 1 1]\n","[1 1]\n","[1 1 1]\n","[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wGzZoFSthNVM","colab_type":"text"},"source":["## III.2) Sử dụng học máy để phân lớp văn bản\n","---\n","Áp dụng một số thuật toán học máy trong phân lớp văn bản [toxic - non toxic]\n","* Navie Bayes\n","* SVM\n","* KNN"]},{"cell_type":"markdown","metadata":{"id":"r1ZK6mWYchNp","colab_type":"text"},"source":["### 1) Thuật toán Naive Bayes\n","---\n","* Naive Bayes Classifiers (NBC) thường được sử dụng trong các bài toán Text Classification\n","* NBC có thời gian training và test rất nhanh. Điều này có được là do giả sử về tính độc lập giữa các thành phần, nếu biết class.\n","\n","* Nếu giả sử về tính độc lập được thoả mãn (dựa vào bản chất của dữ liệu), NBC được cho là cho kết quả tốt hơn so với SVM và logistic regression khi có ít dữ liệu training.\n","\n","* NBC có thể hoạt động với các feature vector mà một phần là liên tục (sử dụng Gaussian Naive Bayes), phần còn lại ở dạng rời rạc (sử dụng Multinomial hoặc Bernoulli).\n","\n","* Khi sử dụng Multinomial Naive Bayes, Laplace smoothing thường được sử dụng để tránh trường hợp 1 thành phần trong test data chưa xuất hiện ở training data."]},{"cell_type":"markdown","metadata":{"id":"N2GJ-U4mcnxd","colab_type":"text"},"source":["#### a) Sử dụng NB với TF-IDF"]},{"cell_type":"code","metadata":{"id":"LwZumM_UpPYw","colab_type":"code","outputId":"312376fb-0ae8-47dd-a6d8-82048371d5e7","executionInfo":{"status":"ok","timestamp":1571210698361,"user_tz":-420,"elapsed":921,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["#Sử dụng mô hình Naive Bayes với TF-IDF\n","from sklearn import naive_bayes as nb\n","#from sklearn.naive_bayes import MultinomialNB  as multiNB\n","MultiNB = nb.MultinomialNB(alpha=0.75)\n","\n","#huấn luyện mô hình với tập huấn luyện Train\n","MultiNB.fit(xtrain_tfidf,train_y)\n","\n","#Đánh giá độ chính xác của mô hình trên tập Test\n","acc_MultiNB = round(MultiNB.score(xtest_tfidf, test_y) * 100, 2)\n","\n","print('Độ chính xác của mô hình: ', acc_MultiNB, '%')\n","print(MultiNB)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Độ chính xác của mô hình:  91.07 %\n","MultinomialNB(alpha=0.75, class_prior=None, fit_prior=True)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ztYiN8k-dTvr","colab_type":"text"},"source":["#### b) Sử dụng NB với BoW\n","---\n","Mô hình này được áp dụng cho các loại dữ liệu mà mỗi thành phần là một giá trị binary - bẳng 0 hoặc 1. Ví dụ: cũng với loại văn bản nhưng thay vì đếm tổng số lần xuất hiện của 1 từ trong văn bản, ta chỉ cần quan tâm từ đó có xuất hiện hay không."]},{"cell_type":"code","metadata":{"id":"-_YfDXGmdarN","colab_type":"code","outputId":"c3a22a19-6284-48b1-b302-62d92e07844e","executionInfo":{"status":"ok","timestamp":1571210863683,"user_tz":-420,"elapsed":842,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["#Sử dụng mô hình Naive Bayes với Bag of words\n","from sklearn import naive_bayes as nb\n","\n","MultiNB = nb.MultinomialNB(alpha=0.75)\n","\n","#huấn luyện mô hình với tập huấn luyện Train\n","MultiNB.fit(xtrain_bow,train_y)\n","\n","#Đánh giá độ chính xác của mô hình trên tập Test\n","acc_MultiNB = round(MultiNB.score(xtest_bow, test_y) * 100, 2)\n","print('Độ chính xác của mô hình NB: ', acc_MultiNB, '%')\n","print(MultiNB)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Độ chính xác của mô hình:  72.21 %\n","MultinomialNB(alpha=0.75, class_prior=None, fit_prior=True)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"F6Tw5NUFeHB9","colab_type":"text"},"source":["### 2)Thuật toán SVM"]},{"cell_type":"markdown","metadata":{"id":"PjFcTWkPePg-","colab_type":"text"},"source":["#### a) Sử dụng SVM với TF-IDF\n","---"]},{"cell_type":"code","metadata":{"id":"j0GiNM-1eUEC","colab_type":"code","outputId":"01438afe-6959-48b9-c66c-dfb1018a50d6","executionInfo":{"status":"ok","timestamp":1571213463273,"user_tz":-420,"elapsed":167848,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["from sklearn.svm import SVC\n","\n","svm_tfidf = SVC(C=0.5, gamma='auto')\n","#Huấn luyện mô hình với dữ liệu Train:\n","svm_tfidf.fit(xtrain_tfidf, train_y)\n","\n","#Xác định độ chính xác của mô hình trên tập Train:\n","acc_svm_tfidf= round(svm_tfidf.score(xtest_tfidf, test_y) * 100, 2)\n","\n","print(\"Độ chính xác của mô hình SVM (TF-IDF): \", acc_svm_tfidf, \"%\")\n","print(\"Các tham số của model SVM:\\n\",svm_tfidf)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Độ chính xác của mô hình SVM (TF-IDF):  59.29 %\n","Các tham số của model SVM:\n"," SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n","    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n","    max_iter=-1, probability=False, random_state=None, shrinking=True,\n","    tol=0.001, verbose=False)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Dehb5ls1e39C","colab_type":"text"},"source":["#### b) Sử dụng SVM với BoW\n","---"]},{"cell_type":"code","metadata":{"id":"-pP3_kAAeLYs","colab_type":"code","outputId":"346ca4bd-087b-4783-ec58-b93cbc064936","executionInfo":{"status":"ok","timestamp":1571213943144,"user_tz":-420,"elapsed":155583,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["from sklearn.svm import SVC\n","\n","svm_bow = SVC(C=0.5,gamma='auto')\n","\n","#Huấn luyện mô hình với dữ liệu Train:\n","svm_bow.fit(xtrain_bow,train_y)\n","\n","#Xác định độ chính xác của mô hình trên tập Train:\n","acc_svm_bow = round(svm_bow.score(xtest_bow, test_y) * 100, 2)\n","\n","print(\"Độ chính xác của mô hình SVC (BoW): \", acc_svm_bow, \"%\")\n","print(\"Các tham số của model SVM:\\n\",svm_bow)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Độ chính xác của mô hình SVC (BoW):  59.29 %\n","Các tham số của model SVM:\n"," SVC(C=0.5, cache_size=200, class_weight=None, coef0=0.0,\n","    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n","    max_iter=-1, probability=False, random_state=None, shrinking=True,\n","    tol=0.001, verbose=False)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OgoulKlrjidr","colab_type":"text"},"source":["### 3) Thuật toán KNN\n","---"]},{"cell_type":"markdown","metadata":{"id":"G_qhumw8mV7h","colab_type":"text"},"source":["#### a) Sử dụng KNN với TF-IDF"]},{"cell_type":"code","metadata":{"id":"X1fg9Bb5jnxE","colab_type":"code","outputId":"cfa959fd-e7e5-4727-d534-b74fe880e12a","executionInfo":{"status":"ok","timestamp":1571213970291,"user_tz":-420,"elapsed":11142,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["from sklearn.neighbors import KNeighborsClassifier\n","#Khởi tạo biến knn sử dụng thuật toán phân lớp KNN, với n = 3\n","knn_tfidf = KNeighborsClassifier(n_neighbors = 10)\n","\n","#Huấn luyện mô hình với tập dữ liệu train:\n","knn_tfidf.fit(xtrain_tfidf, train_y)\n","\n","#Đánh giá độ chính xác của mô hình trên tập test:\n","acc_knn_tfidf = round(knn_tfidf.score(xtest_tfidf, test_y) * 100, 2)\n","\n","print(\"Độ chính xác của mô hình KNN (TF-IDF): \", acc_knn_tfidf, \"%\")\n","print(\"Các tham số của Model KNN: \\n\",knn_tfidf)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Độ chính xác của mô hình KNN (TF-IDF):  67.91 %\n","Các tham số của Model KNN: \n"," KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n","                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n","                     weights='uniform')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fR9bd1Olmngv","colab_type":"text"},"source":["#### b) Sử dụng KNN với BoW"]},{"cell_type":"code","metadata":{"id":"ohPS2hR5mt2N","colab_type":"code","outputId":"dce8f128-3460-4e8c-ab06-78444bd399cf","executionInfo":{"status":"ok","timestamp":1571214015771,"user_tz":-420,"elapsed":10641,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["from sklearn.neighbors import KNeighborsClassifier\n","#Khởi tạo biến knn sử dụng thuật toán phân lớp KNN, với n = 3\n","knn_bow = KNeighborsClassifier(n_neighbors = 10)\n","\n","#Huấn luyện mô hình với tập dữ liệu train:\n","knn_bow.fit(xtrain_tfidf, train_y)\n","\n","#Đánh giá độ chính xác của mô hình trên tập test:\n","acc_knn_bow = round(knn_bow.score(xtest_tfidf, test_y) * 100, 2)\n","\n","print(\"Độ chính xác của mô hình KNN (BoW): \", acc_knn_bow, \"%\")\n","print(\"Các tham số của Model KNN: \\n\",knn_bow)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Độ chính xác của mô hình KNN (BoW):  67.91 %\n","Các tham số của Model KNN: \n"," KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n","                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n","                     weights='uniform')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2HFGgnejU0_v","colab_type":"text"},"source":["## IV) SỬ DỤNG MÔ HÌNH HỌC SÂU - LSTM TRONG PHÂN LỚP VĂN BẢN\n","---\n","Sử dụng mạng LTSM phân lớp văn bản.\n","\n","![alt text](https://miro.medium.com/max/989/1*8BdmU3wYefT7vDZRWWOL1Q.png)\n"]},{"cell_type":"code","metadata":{"id":"40tD8b2NoxKr","colab_type":"code","outputId":"275f8fec-8947-4cff-a646-253c8ffe0968","executionInfo":{"status":"ok","timestamp":1571362749574,"user_tz":-420,"elapsed":39249,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":447}},"source":["#------------NẾU CẦN ----------------------------------------------------\n","#Đọc lại tập dữ liệu sau khi đã loại bỏ dòng rỗng:\n","#Tải file dữ liệu sau khi đã tiền xử lý\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import pandas as pd\n","path='/content/drive/My Drive/Colab Notebooks/10Project/Data_tweet/data_finish_no_null.csv'\n","data_NLP = pd.read_csv(path)\n","data_NLP.head(10)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>tweet_ok</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>woman complain clean house man always take trash</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>boy dats dwn bad cuffin dat hoe st place</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>dawg ever fuck bitch start cry confuse shit</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>look like tranny</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>shit hear might true might faker bitch tell ya</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>shit blow faithful somebody still fuck hoe</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1</td>\n","      <td>sit hate another bitch get much shit go</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>cause tire big bitch come us skinny girls</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1</td>\n","      <td>might get ya bitch back thats</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1</td>\n","      <td>hobbies include fight mariam bitch</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   class                                          tweet_ok\n","0      0  woman complain clean house man always take trash\n","1      1          boy dats dwn bad cuffin dat hoe st place\n","2      1       dawg ever fuck bitch start cry confuse shit\n","3      1                                  look like tranny\n","4      1    shit hear might true might faker bitch tell ya\n","5      1        shit blow faithful somebody still fuck hoe\n","6      1           sit hate another bitch get much shit go\n","7      1         cause tire big bitch come us skinny girls\n","8      1                     might get ya bitch back thats\n","9      1                hobbies include fight mariam bitch"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"IY4QZZM0n74n","colab_type":"text"},"source":["\n"]},{"cell_type":"markdown","metadata":{"id":"GyyQRVpQoR35","colab_type":"text"},"source":["\n","#### Thư viện Spacy:\n","---\n","SpaCy là một thư viện xử lý ngôn ngữ tự nhiên với các ví dụ tuyệt vời, tài liệu API và các ứng dụng demo. Thư viện được viết bằng ngôn ngữ Cython là phần mở rộng C của Python. Một tính năng tuyệt vời khác của spaCy là một kiến trúc được thiết kế để xử lý toàn bộ tài liệu mà không cần phải chia tài liệu thành các cụm từ. spaCy chứa các mô hình thống kê được huấn luyện trước và vector từ vựng (word vector), và cũng hỗ trợ việc token hóa cho hơn 49 ngôn ngữ. Tính năng đáng chú ý của spaCy là tốc độ xử lý nhanh trong các mô hình mạng thần kinh tích chập dùng để gắn thẻ, phân tích cú pháp và nhận dạng thực thể được đặt tên và dễ dàng tích hợp học sâu (deep learning)\n","https://spacy.io/."]},{"cell_type":"code","metadata":{"id":"3sR0cARERwD-","colab_type":"code","outputId":"18d42437-ffe9-4ac7-857b-350e3cd5b388","executionInfo":{"status":"ok","timestamp":1571362981201,"user_tz":-420,"elapsed":226262,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["#\n","import spacy\n","!python -m spacy download en_core_web_lg"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting en_core_web_lg==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz#egg=en_core_web_lg==2.1.0\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz (826.9MB)\n","\u001b[K     |████████████████████████████████| 826.9MB 65.1MB/s \n","\u001b[?25hBuilding wheels for collected packages: en-core-web-lg\n","  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.1.0-cp36-none-any.whl size=828255076 sha256=fac4f55843ba637cf39dfe9643d17dca324063d8bd3ecb74ab38a1e23cb674c9\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-hswcfkl_/wheels/b4/d7/70/426d313a459f82ed5e06cc36a50e2bb2f0ec5cb31d8e0bdf09\n","Successfully built en-core-web-lg\n","Installing collected packages: en-core-web-lg\n","Successfully installed en-core-web-lg-2.1.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_lg')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fAo6U04STqm5","colab_type":"code","colab":{}},"source":["nlp = spacy.load('/usr/local/lib/python3.6/dist-packages/en_core_web_lg/en_core_web_lg-2.1.0')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rHcfhvMVtcIq","colab_type":"code","outputId":"303f7c55-0cd7-449e-ab4d-672888160a0e","executionInfo":{"status":"ok","timestamp":1571363312257,"user_tz":-420,"elapsed":616,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["text = \"Amazon.com, Inc., doing business as Amazon, is an American electronic commerce and cloud computing company based in Seattle, Washington, that was founded by Jeff Bezos on July 5, 1994. The tech giant is the largest Internet retailer in the world as measured by revenue and market capitalization, and second largest after Alibaba Group in terms of total sales. The amazon.com website started as an online bookstore and later diversified to sell video downloads/streaming, MP3 downloads/streaming, audiobook downloads/streaming, software, video games, electronics, apparel, furniture, food, toys, and jewelry. The company also produces consumer electronics - Kindle e-readers, Fire tablets, Fire TV, and Echo - and is the world's largest provider of cloud infrastructure services (IaaS and PaaS). Amazon also sells certain low-end products under its in-house brand AmazonBasics.\"\n","text1=\"New York is the biggest city on the world\"\n","### Parse the text with spaCy\n","### Our 'document' variable now contains a parsed version of text.\n","document = nlp(text1)\n","### print out all the named entities that were detected\n","for entity in document.ents:\n","      print(entity.text, entity.label_) "],"execution_count":0,"outputs":[{"output_type":"stream","text":["New York GPE\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HQ8LGDSbPpmO","colab_type":"code","colab":{}},"source":["#xây dựng một bảng tương ứng, mà mỗi từ khác nhau sẽ được ký hiệu bởi số nguyên khác nhau duy nhất.\n","#Keras hỗ trợ trong việc xây dựng bảng này với hàm: Keras.preprocessing.Text.Tokenizer\n","from keras.preprocessing.text import Tokenizer\n","import numpy as np\n","\n","tokenizer = Tokenizer(num_words=30000)\n","tokenizer.fit_on_texts(data_NLP['tweet_ok'])\n","embeddings_index = np.zeros((30000 + 1, 300))\n","for word, idx in tokenizer.word_index.items():\n","    try:\n","        embedding = nlp.vocab[word].vector\n","        embeddings_index[idx] = embedding\n","    except:\n","        pass"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"otXFrs7OQIVP","colab_type":"code","outputId":"98526e6d-26f8-4e2e-8165-d0f7bb8764a6","executionInfo":{"status":"ok","timestamp":1571363426615,"user_tz":-420,"elapsed":610,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["embeddings_index.shape\n","embeddings_index[10]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(30001, 300)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"kwDbwnorVr4i","colab_type":"text"},"source":["#### a) Chuẩn bị tập Train/Test\n","---\n"]},{"cell_type":"code","metadata":{"id":"GfnG59RjJA8S","colab_type":"code","colab":{}},"source":["#Lấy dữ liệu \n","from sklearn.preprocessing import LabelEncoder\n","from keras.utils import np_utils\n","X=data_NLP['tweet_ok']\n","y=data_NLP['class']\n","\n","encoder = LabelEncoder()\n","y=encoder.fit_transform(y)\n","Y=np_utils.to_categorical(y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N-x9GUGfOVBf","colab_type":"code","outputId":"c927cca9-9257-4aee-c386-753484412d51","executionInfo":{"status":"ok","timestamp":1571216208616,"user_tz":-420,"elapsed":1202,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["print(type(Y))\n","print(Y)\n","print(Y.shape)\n","print(y)\n","print(y.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'numpy.ndarray'>\n","[[1. 0.]\n"," [0. 1.]\n"," [0. 1.]\n"," ...\n"," [1. 0.]\n"," [1. 0.]\n"," [1. 0.]]\n","(56657, 2)\n","[0 1 1 ... 0 0 0]\n","(56657,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SgUvuk-2PB0b","colab_type":"code","outputId":"dbada1d3-18e8-414c-93ba-eb64e5e0f221","executionInfo":{"status":"ok","timestamp":1571363544632,"user_tz":-420,"elapsed":808,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, random_state = 40, stratify=Y)\n","print('Tập Train (80%): ', x_train.shape)\n","print('Tập Test (20%): ', x_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Tập Train (80%):  (45325,)\n","Tập Test (20%):  (11332,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3Mnc24PEzcxK","colab_type":"text"},"source":["#### b)Xây dựng model\n","---"]},{"cell_type":"code","metadata":{"id":"6mf2pLt7U5FM","colab_type":"code","colab":{}},"source":["from sklearn.base import BaseEstimator, TransformerMixin\n","from keras.models import Sequential\n","from keras.layers import Activation, Dense, Dropout, LSTM, Embedding\n","from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import np_utils\n","from keras.layers import Dense, Input, LSTM, Bidirectional, Activation, Conv1D, GRU, TimeDistributed\n","from keras.layers import Dropout, Embedding, GlobalMaxPooling1D, MaxPooling1D, Add, Flatten, SpatialDropout1D\n","from keras.layers import GlobalAveragePooling1D, BatchNormalization, concatenate\n","from keras.layers import Reshape, merge, Concatenate, Lambda, Average\n","from keras import backend as K\n","from keras.engine.topology import Layer\n","from keras import initializers, regularizers, constraints\n","from keras.models import Model\n","from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lO94APcbU3mg","colab_type":"code","colab":{}},"source":["class KerasTextClassifier(BaseEstimator, TransformerMixin):\n","  '''Wrapper class for keras text classification models that takes raw text as input.'''\n","  \n","  def __init__(self, max_words=30000, input_length=20, emb_dim=300, n_classes=2, epochs=40, batch_size=64, emb_idx=0):\n","    self.max_words = max_words\n","    self.input_length = input_length\n","    self.emb_dim = emb_dim\n","    self.n_classes = n_classes\n","    self.epochs = epochs\n","    self.bs = batch_size\n","    self.embeddings_index = emb_idx\n","    self.tokenizer = Tokenizer(num_words=self.max_words+1, lower=True, split=' ')\n","    self.model = self._get_model()\n","    return self.model.summary()\n","    \n","  def _get_model(self):\n","    input_text = Input((self.input_length,))\n","    text_embedding = Embedding(input_dim=self.max_words+1, output_dim=self.emb_dim, input_length=self.input_length, \n","                               mask_zero=False, weights=[self.embeddings_index], trainable=False)(input_text)\n","    \n","    \n","    text_embedding = SpatialDropout1D(0.4)(text_embedding)\n","    bilstm =(LSTM(units=50,  recurrent_dropout=0.2, return_sequences = True))(text_embedding)\n","    x = Dropout(0.2)(bilstm)\n","    x =(LSTM(units=50,  recurrent_dropout=0.2))(x)\n","    out = Dense(units=self.n_classes, activation=\"softmax\")(x)\n","    model = Model(inputs=[input_text],outputs=[out])\n","    model.compile(optimizer=\"adam\",\n","    loss=\"categorical_crossentropy\",\n","    metrics=[\"accuracy\"])\n","    return model\n","  \n","  def _get_sequences(self, texts):\n","    seqs = self.tokenizer.texts_to_sequences(texts)\n","    return pad_sequences(seqs, maxlen=self.input_length, value=0)\n","  \n","  def _preprocess(self, texts):\n","    return [prepare_data(x) for x in texts]\n","  \n","  def fit(self, X, y):\n","    '''Fit the vocabulary and the model.\n","       :params: X: list of texts. y: labels.\n","    '''\n","    self.tokenizer.fit_on_texts(X)\n","    self.tokenizer.word_index = {e: i for e,i in self.tokenizer.word_index.items() if i <= self.max_words}\n","    self.tokenizer.word_index[self.tokenizer.oov_token] = self.max_words + 1\n","    seqs = self._get_sequences(self._preprocess(X))\n","    self.model.fit([seqs ], y, batch_size=self.bs, epochs=self.epochs, validation_split=0.1)\n","  \n","  #Hàm predict_proba cho biết xác xuất dự đoán comment thuộc lớp nào\n","  def predict_proba(self, X, y=None):\n","    seqs = self._get_sequences(self._preprocess(X))\n","    return self.model.predict(seqs)\n","  \n","  #Hàm predict: chuyển đổi về class có tỷ lệ dự đoán cao nhất\n","  def predict(self, X, y=None):\n","    return np.argmax(self.predict_proba(X), axis=1)\n","  \n","  def score(self, X, y):\n","    y_pred = self.predict(X)\n","    return accuracy_score(np.argmax(y, axis=1), y_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hv8JhKqrVD7c","colab_type":"code","outputId":"c2ef6065-1512-4755-ac1e-9c083deb2d8c","executionInfo":{"status":"ok","timestamp":1571364239608,"user_tz":-420,"elapsed":2035,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":386}},"source":["#Khai báo sử dung Model\n","text_model = KerasTextClassifier(emb_idx= embeddings_index)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_4 (InputLayer)         (None, 20)                0         \n","_________________________________________________________________\n","embedding_4 (Embedding)      (None, 20, 300)           9000300   \n","_________________________________________________________________\n","spatial_dropout1d_4 (Spatial (None, 20, 300)           0         \n","_________________________________________________________________\n","lstm_8 (LSTM)                (None, 20, 50)            70200     \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 20, 50)            0         \n","_________________________________________________________________\n","lstm_9 (LSTM)                (None, 50)                20200     \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 2)                 102       \n","=================================================================\n","Total params: 9,090,802\n","Trainable params: 90,502\n","Non-trainable params: 9,000,300\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6GTCAiWnXPhu","colab_type":"text"},"source":["### c)Huấn luyện mô hình\n","---\n"]},{"cell_type":"code","metadata":{"id":"Hl0D1U7-XJqq","colab_type":"code","outputId":"a0779995-5c43-404c-b2a8-6cbb3f2045cf","executionInfo":{"status":"ok","timestamp":1571365668844,"user_tz":-420,"elapsed":1422200,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["text_model.fit(x_train,y_train)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 40792 samples, validate on 4533 samples\n","Epoch 1/40\n","40792/40792 [==============================] - 37s 905us/step - loss: 0.3256 - acc: 0.8722 - val_loss: 0.2434 - val_acc: 0.9080\n","Epoch 2/40\n","40792/40792 [==============================] - 35s 862us/step - loss: 0.2426 - acc: 0.9128 - val_loss: 0.1973 - val_acc: 0.9314\n","Epoch 3/40\n","40792/40792 [==============================] - 35s 866us/step - loss: 0.2115 - acc: 0.9245 - val_loss: 0.1847 - val_acc: 0.9367\n","Epoch 4/40\n","40792/40792 [==============================] - 35s 855us/step - loss: 0.1921 - acc: 0.9317 - val_loss: 0.1684 - val_acc: 0.9433\n","Epoch 5/40\n","40792/40792 [==============================] - 35s 856us/step - loss: 0.1806 - acc: 0.9357 - val_loss: 0.1692 - val_acc: 0.9446\n","Epoch 6/40\n","40792/40792 [==============================] - 35s 865us/step - loss: 0.1699 - acc: 0.9405 - val_loss: 0.1627 - val_acc: 0.9460\n","Epoch 7/40\n","40792/40792 [==============================] - 35s 860us/step - loss: 0.1648 - acc: 0.9415 - val_loss: 0.1656 - val_acc: 0.9471\n","Epoch 8/40\n","40792/40792 [==============================] - 35s 857us/step - loss: 0.1571 - acc: 0.9437 - val_loss: 0.1611 - val_acc: 0.9453\n","Epoch 9/40\n","40792/40792 [==============================] - 35s 861us/step - loss: 0.1515 - acc: 0.9462 - val_loss: 0.1596 - val_acc: 0.9473\n","Epoch 10/40\n","40792/40792 [==============================] - 35s 862us/step - loss: 0.1459 - acc: 0.9477 - val_loss: 0.1608 - val_acc: 0.9490\n","Epoch 11/40\n","40792/40792 [==============================] - 35s 863us/step - loss: 0.1430 - acc: 0.9493 - val_loss: 0.1562 - val_acc: 0.9488\n","Epoch 12/40\n","40792/40792 [==============================] - 35s 861us/step - loss: 0.1398 - acc: 0.9502 - val_loss: 0.1560 - val_acc: 0.9499\n","Epoch 13/40\n","40792/40792 [==============================] - 35s 856us/step - loss: 0.1345 - acc: 0.9524 - val_loss: 0.1554 - val_acc: 0.9486\n","Epoch 14/40\n","40792/40792 [==============================] - 35s 867us/step - loss: 0.1312 - acc: 0.9536 - val_loss: 0.1543 - val_acc: 0.9499\n","Epoch 15/40\n","40792/40792 [==============================] - 36s 871us/step - loss: 0.1273 - acc: 0.9549 - val_loss: 0.1544 - val_acc: 0.9488\n","Epoch 16/40\n","40792/40792 [==============================] - 35s 861us/step - loss: 0.1266 - acc: 0.9557 - val_loss: 0.1669 - val_acc: 0.9497\n","Epoch 17/40\n","40792/40792 [==============================] - 35s 866us/step - loss: 0.1215 - acc: 0.9575 - val_loss: 0.1667 - val_acc: 0.9504\n","Epoch 18/40\n","40792/40792 [==============================] - 35s 862us/step - loss: 0.1219 - acc: 0.9562 - val_loss: 0.1700 - val_acc: 0.9519\n","Epoch 19/40\n","40792/40792 [==============================] - 35s 863us/step - loss: 0.1168 - acc: 0.9591 - val_loss: 0.1625 - val_acc: 0.9521\n","Epoch 20/40\n","40792/40792 [==============================] - 35s 861us/step - loss: 0.1158 - acc: 0.9582 - val_loss: 0.1605 - val_acc: 0.9468\n","Epoch 21/40\n","40792/40792 [==============================] - 35s 865us/step - loss: 0.1141 - acc: 0.9590 - val_loss: 0.1618 - val_acc: 0.9499\n","Epoch 22/40\n","40792/40792 [==============================] - 35s 863us/step - loss: 0.1121 - acc: 0.9601 - val_loss: 0.1733 - val_acc: 0.9526\n","Epoch 23/40\n","40792/40792 [==============================] - 36s 879us/step - loss: 0.1101 - acc: 0.9609 - val_loss: 0.1697 - val_acc: 0.9495\n","Epoch 24/40\n","40792/40792 [==============================] - 36s 877us/step - loss: 0.1073 - acc: 0.9611 - val_loss: 0.1674 - val_acc: 0.9508\n","Epoch 25/40\n","40792/40792 [==============================] - 36s 878us/step - loss: 0.1049 - acc: 0.9621 - val_loss: 0.1658 - val_acc: 0.9519\n","Epoch 26/40\n","40792/40792 [==============================] - 36s 882us/step - loss: 0.1043 - acc: 0.9628 - val_loss: 0.1631 - val_acc: 0.9512\n","Epoch 27/40\n","40792/40792 [==============================] - 37s 897us/step - loss: 0.1027 - acc: 0.9630 - val_loss: 0.1677 - val_acc: 0.9530\n","Epoch 28/40\n","40792/40792 [==============================] - 36s 890us/step - loss: 0.1004 - acc: 0.9643 - val_loss: 0.1689 - val_acc: 0.9548\n","Epoch 29/40\n","40792/40792 [==============================] - 37s 898us/step - loss: 0.1004 - acc: 0.9636 - val_loss: 0.1734 - val_acc: 0.9501\n","Epoch 30/40\n","40792/40792 [==============================] - 36s 877us/step - loss: 0.0971 - acc: 0.9649 - val_loss: 0.1791 - val_acc: 0.9519\n","Epoch 31/40\n","40792/40792 [==============================] - 35s 865us/step - loss: 0.0961 - acc: 0.9656 - val_loss: 0.1776 - val_acc: 0.9521\n","Epoch 32/40\n","40792/40792 [==============================] - 35s 859us/step - loss: 0.0980 - acc: 0.9647 - val_loss: 0.1675 - val_acc: 0.9508\n","Epoch 33/40\n","40792/40792 [==============================] - 35s 853us/step - loss: 0.0941 - acc: 0.9659 - val_loss: 0.1768 - val_acc: 0.9510\n","Epoch 34/40\n","40792/40792 [==============================] - 35s 860us/step - loss: 0.0939 - acc: 0.9659 - val_loss: 0.1684 - val_acc: 0.9510\n","Epoch 35/40\n","40792/40792 [==============================] - 35s 858us/step - loss: 0.0929 - acc: 0.9665 - val_loss: 0.1886 - val_acc: 0.9526\n","Epoch 36/40\n","40792/40792 [==============================] - 35s 856us/step - loss: 0.0933 - acc: 0.9671 - val_loss: 0.1747 - val_acc: 0.9501\n","Epoch 37/40\n","40792/40792 [==============================] - 35s 859us/step - loss: 0.0924 - acc: 0.9662 - val_loss: 0.1672 - val_acc: 0.9512\n","Epoch 38/40\n","40792/40792 [==============================] - 35s 854us/step - loss: 0.0897 - acc: 0.9680 - val_loss: 0.1822 - val_acc: 0.9517\n","Epoch 39/40\n","40792/40792 [==============================] - 35s 857us/step - loss: 0.0891 - acc: 0.9666 - val_loss: 0.1703 - val_acc: 0.9541\n","Epoch 40/40\n","40792/40792 [==============================] - 35s 866us/step - loss: 0.0894 - acc: 0.9673 - val_loss: 0.1696 - val_acc: 0.9510\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IzQNzJlNXkLx","colab_type":"text"},"source":["### d) Đánh giá độ chính xác của mô hình trên tập test\n","---\n"]},{"cell_type":"code","metadata":{"id":"QX24e4g4Xoyu","colab_type":"code","outputId":"2cdfaafd-f845-4253-be71-f2705f0bc901","executionInfo":{"status":"ok","timestamp":1571365861195,"user_tz":-420,"elapsed":5206,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["acc_LSTM = text_model.score(x_test, y_test)\n","print(\"Độ chính xác của mô hình LSTM: \", round(acc_LSTM*100,2), \"%\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Độ chính xác của mô hình LSTM:  94.67 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_MCZTentJQgU","colab_type":"code","outputId":"e23e7c40-980f-447a-dd2c-9f01ec9424a1","executionInfo":{"status":"ok","timestamp":1571374111804,"user_tz":-420,"elapsed":8745,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":168}},"source":["#Dự đoán với tập test\n","a = text_model.predict_proba(x_test)\n","b = text_model.predict(x_test)\n","for i in range(1,10):\n","    print(a[i],'--',b[i])\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[6.2105624e-04 9.9937892e-01] -- 1\n","[0.00649963 0.9935003 ] -- 1\n","[0.998662   0.00133796] -- 0\n","[0.9988085  0.00119151] -- 0\n","[0.8254765 0.1745235] -- 0\n","[0.9637988  0.03620114] -- 0\n","[0.8927987  0.10720136] -- 0\n","[9.9998343e-01 1.6516107e-05] -- 0\n","[0.9978721  0.00212794] -- 0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3kKt5SH3XyAG","colab_type":"text"},"source":["## V)THƯ VIỆN ELI5\n","---\n","ELI5 là một gói thư viện của Python trợ giúp việc gỡ lỗi các mô hình học máy cho bài toán phân lớp và hỗ trợ giải thích các dự đoán. ELI5 cũng thực hiện một số thuật toán để kiêm tra các mô hình hộp đen. \n","\n","https://eli5.readthedocs.io/en/latest/overview.html"]},{"cell_type":"code","metadata":{"id":"Zp1-26CFbU1z","colab_type":"code","outputId":"39e0db2b-5f35-4bdf-be48-a9e48c45b508","executionInfo":{"status":"ok","timestamp":1571367594843,"user_tz":-420,"elapsed":5814,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["!pip install eli5"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting eli5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n","\u001b[K     |████████████████████████████████| 112kB 3.5MB/s \n","\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.5)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n","Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.16.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.3.1)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.21.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.12.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.10.3)\n","Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (19.2.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (0.14.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n","Installing collected packages: eli5\n","Successfully installed eli5-0.10.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WxooKctG4bos","colab_type":"code","colab":{}},"source":["for i in range(0,100):\n","    print(i,')',y_test[i],'--',x_test.iloc[i])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fg6uHeIrbaSA","colab_type":"code","outputId":"b69717cf-c52c-463b-83ef-cc55f597751b","executionInfo":{"status":"ok","timestamp":1571371879796,"user_tz":-420,"elapsed":61236,"user":{"displayName":"Nam Đặng Văn","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAqrORj-P8fXkEOcO3AzrgZkp6R-z4lJAIegEvJkw=s64","userId":"08158656345609809641"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import eli5\n","from eli5.lime import TextExplainer\n","from IPython.display import display, HTML\n","\n","for idx in x_test.index[300:320]:\n","  te = TextExplainer(random_state=42)\n","  te.fit(prepare_data(x_test[idx]), text_model.predict_proba, )\n","  print(idx)\n","  print(\"Real Class:\",  [\"Non Toxic\" if x == 0 else \"Toxic\" for x in [data_NLP.iloc[idx]['class']]])\n","  print(\"Text Tweet:\", data_NLP.iloc[idx]['tweet_ok'])\n","  print(\"ELI5 Predicted Class:\")\n","  HTML(display((te.show_prediction(target_names=[ 'Non Toxic','Toxic',]))))\n"," "],"execution_count":0,"outputs":[{"output_type":"stream","text":["21440\n","Real Class: ['Toxic']\n","Text uncleaned tweet: deal breaker yo pussy smell like sweaty hoop short\n","ELI5 Predicted Class:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=Toxic\n","    \n","</b>\n","\n","    \n","    (probability <b>0.993</b>, score <b>4.936</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +5.652\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 95.29%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.716\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"background-color: hsl(0, 100.00%, 99.31%); opacity: 0.80\" title=\"-0.025\">deal</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.45%); opacity: 0.81\" title=\"0.261\">breaker</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.18%); opacity: 0.84\" title=\"1.455\">yo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"8.301\">pussy</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.50%); opacity: 0.84\" title=\"1.575\">smell</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.84%); opacity: 0.81\" title=\"0.327\">like</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.14%); opacity: 0.80\" title=\"-0.104\">sweaty</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.64%); opacity: 0.81\" title=\"-0.349\">hoop</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.68%); opacity: 0.81\" title=\"-0.595\">short</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["53211\n","Real Class: ['Non Toxic']\n","Text uncleaned tweet: finally find way delete old tweet might find useful well deletetweets\n","ELI5 Predicted Class:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=Non Toxic\n","    \n","</b>\n","\n","    \n","    (probability <b>1.000</b>, score <b>-9.734</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +9.078\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 96.82%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +0.655\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"background-color: hsl(120, 100.00%, 63.26%); opacity: 0.98\" title=\"1.077\">finally</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 62.73%); opacity: 0.98\" title=\"1.099\">find</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.16%); opacity: 0.90\" title=\"0.581\">way</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.82%); opacity: 0.88\" title=\"0.458\">delete</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.46%); opacity: 0.96\" title=\"0.946\">old</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.02%); opacity: 0.80\" title=\"0.017\">tweet</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.60%); opacity: 0.89\" title=\"0.565\">might</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.55%); opacity: 1.00\" title=\"1.193\">find</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.37%); opacity: 0.88\" title=\"0.472\">useful</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 61.80%); opacity: 0.99\" title=\"1.139\">well</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.216\">deletetweets</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["20085\n","Real Class: ['Toxic']\n","Text uncleaned tweet: yeah check connection fuck wifi check lil bitch nigga\n","ELI5 Predicted Class:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=Toxic\n","    \n","</b>\n","\n","    \n","    (probability <b>1.000</b>, score <b>8.993</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +9.465\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 97.55%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.472\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"background-color: hsl(120, 100.00%, 96.33%); opacity: 0.81\" title=\"0.168\">yeah</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.31%); opacity: 0.80\" title=\"-0.055\">check</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.43%); opacity: 0.81\" title=\"0.161\">connection</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.57%); opacity: 0.89\" title=\"2.372\">fuck</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.31%); opacity: 0.81\" title=\"-0.169\">wifi</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.84%); opacity: 0.83\" title=\"-0.718\">check</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.77%); opacity: 0.82\" title=\"0.442\">lil</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"5.091\">bitch</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 65.86%); opacity: 0.96\" title=\"4.059\">nigga</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["18063\n","Real Class: ['Toxic']\n","Text uncleaned tweet: keep stoop hoe know better\n","ELI5 Predicted Class:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=Toxic\n","    \n","</b>\n","\n","    \n","    (probability <b>0.991</b>, score <b>4.684</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +5.328\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 95.44%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.644\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"background-color: hsl(0, 100.00%, 95.58%); opacity: 0.81\" title=\"-0.352\">keep</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.39%); opacity: 0.82\" title=\"0.911\">stoop</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"8.181\">hoe</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.61%); opacity: 0.81\" title=\"0.467\">know</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.74%); opacity: 0.80\" title=\"0.135\">better</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["37531\n","Real Class: ['Non Toxic']\n","Text uncleaned tweet: great time vacation barharbor soybu fitmom momlife maine\n","ELI5 Predicted Class:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=Non Toxic\n","    \n","</b>\n","\n","    \n","    (probability <b>1.000</b>, score <b>-9.655</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +9.047\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 96.98%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +0.609\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"background-color: hsl(120, 100.00%, 65.54%); opacity: 0.96\" title=\"1.290\">great</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.596\">time</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 68.66%); opacity: 0.94\" title=\"1.126\">vacation</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.37%); opacity: 0.89\" title=\"0.708\">barharbor</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.87%); opacity: 0.89\" title=\"0.730\">soybu</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.50%); opacity: 0.92\" title=\"0.984\">fitmom</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 69.49%); opacity: 0.94\" title=\"1.084\">momlife</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 62.98%); opacity: 0.98\" title=\"1.429\">maine</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["9200\n","Real Class: ['Non Toxic']\n","Text uncleaned tweet: friends let friends become guidos themoreyouknow\n","ELI5 Predicted Class:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=Non Toxic\n","    \n","</b>\n","\n","    \n","    (probability <b>1.000</b>, score <b>-10.104</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +9.488\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 97.05%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +0.616\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"background-color: hsl(120, 100.00%, 60.32%); opacity: 1.00\" title=\"2.063\">friends</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 69.20%); opacity: 0.94\" title=\"1.437\">let</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"2.087\">friends</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 65.84%); opacity: 0.96\" title=\"1.666\">become</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.80%); opacity: 0.90\" title=\"1.078\">guidos</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.34%); opacity: 0.91\" title=\"1.107\">themoreyouknow</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["15790\n","Real Class: ['Toxic']\n","Text uncleaned tweet: mygirlfriendnotallowedto milkshakes let hoe bring one boy yard watch\n","ELI5 Predicted Class:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=Toxic\n","    \n","</b>\n","\n","    \n","    (probability <b>0.993</b>, score <b>4.965</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +5.663\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 95.38%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.698\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"background-color: hsl(120, 100.00%, 98.50%); opacity: 0.80\" title=\"0.083\">mygirlfriendnotallowedto</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.92%); opacity: 0.81\" title=\"0.232\">milkshakes</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.55%); opacity: 0.83\" title=\"1.329\">let</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"9.049\">hoe</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.16%); opacity: 0.83\" title=\"1.221\">bring</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.31%); opacity: 0.80\" title=\"0.028\">one</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.22%); opacity: 0.80\" title=\"0.201\">boy</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.29%); opacity: 0.80\" title=\"-0.029\">yard</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.12%); opacity: 0.81\" title=\"-0.448\">watch</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["48571\n","Real Class: ['Non Toxic']\n","Text uncleaned tweet: wait summer tbh summersunglassesgirl smile\n","ELI5 Predicted Class:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=Non Toxic\n","    \n","</b>\n","\n","    \n","    (probability <b>1.000</b>, score <b>-10.002</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +9.400\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 97.08%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +0.601\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"background-color: hsl(120, 100.00%, 61.49%); opacity: 0.99\" title=\"1.955\">wait</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.13%); opacity: 1.00\" title=\"2.055\">summer</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 62.07%); opacity: 0.99\" title=\"1.913\">tbh</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 65.71%); opacity: 0.96\" title=\"1.656\">summersunglassesgirl</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"2.064\">smile</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["26521\n","Real Class: ['Non Toxic']\n","Text uncleaned tweet: followi hope well world\n","ELI5 Predicted Class:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=Non Toxic\n","    \n","</b>\n","\n","    \n","    (probability <b>0.999</b>, score <b>-6.841</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +6.181\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 95.82%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +0.660\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"background-color: hsl(120, 100.00%, 74.16%); opacity: 0.91\" title=\"1.249\">followi</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"2.331\">hope</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.04%); opacity: 0.92\" title=\"1.398\">well</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.94%); opacity: 0.87\" title=\"0.869\">world</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["55587\n","Real Class: ['Non Toxic']\n","Text uncleaned tweet: baby evenflo maestro harness booster car seat provo bouncingbaby\n","ELI5 Predicted Class:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=Non Toxic\n","    \n","</b>\n","\n","    \n","    (probability <b>0.969</b>, score <b>-3.426</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +2.578\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 90.82%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +0.848\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"background-color: hsl(120, 100.00%, 72.85%); opacity: 0.91\" title=\"0.713\">baby</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.76%); opacity: 0.85\" title=\"-0.284\">evenflo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.24%); opacity: 0.82\" title=\"-0.119\">maestro</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.41%); opacity: 0.85\" title=\"-0.323\">harness</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.30%); opacity: 0.82\" title=\"-0.097\">booster</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.13%); opacity: 0.89\" title=\"-0.558\">car</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-1.241\">seat</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.64%); opacity: 0.82\" title=\"-0.133\">provo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.41%); opacity: 0.86\" title=\"0.384\">bouncingbaby</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["20918\n","Real Class: ['Toxic']\n","Text uncleaned tweet: already fuck dude nice humor bitch cross line first motherfucking\n","ELI5 Predicted Class:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=Toxic\n","    \n","</b>\n","\n","    \n","    (probability <b>0.994</b>, score <b>5.133</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +5.701\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 96.02%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.569\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"background-color: hsl(0, 100.00%, 99.40%); opacity: 0.80\" title=\"-0.018\">already</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.66%); opacity: 0.86\" title=\"2.148\">fuck</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.40%); opacity: 0.80\" title=\"0.142\">dude</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.14%); opacity: 0.82\" title=\"-0.693\">nice</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.43%); opacity: 0.82\" title=\"0.658\">humor</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"7.090\">bitch</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.06%); opacity: 0.82\" title=\"0.834\">cross</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.24%); opacity: 0.83\" title=\"1.087\">line</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.37%); opacity: 0.81\" title=\"-0.325\">first</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.46%); opacity: 0.82\" title=\"-0.653\">motherfucking</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["45158\n","Real Class: ['Non Toxic']\n","Text uncleaned tweet: beachbody bull dominate bull direct whatever want yo\n","ELI5 Predicted Class:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=Non Toxic\n","    \n","</b>\n","\n","    \n","    (probability <b>1.000</b>, score <b>-10.032</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +9.457\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 97.19%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +0.574\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"background-color: hsl(120, 100.00%, 78.77%); opacity: 0.88\" title=\"0.844\">beachbody</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"2.086\">bull</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 68.40%); opacity: 0.94\" title=\"1.490\">dominate</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.73%); opacity: 0.99\" title=\"2.032\">bull</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.33%); opacity: 0.89\" title=\"0.927\">direct</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 66.84%); opacity: 0.95\" title=\"1.596\">whatever</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.34%); opacity: 0.83\" title=\"0.274\">want</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.86%); opacity: 0.82\" title=\"-0.253\">yo</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["21790\n","Real Class: ['Toxic']\n","Text uncleaned tweet: hoe get outta hand mane\n","ELI5 Predicted Class:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=Toxic\n","    \n","</b>\n","\n","    \n","    (probability <b>0.989</b>, score <b>4.470</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +4.998\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 95.85%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.528\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"6.782\">hoe</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.62%); opacity: 0.81\" title=\"0.492\">get</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.04%); opacity: 0.81\" title=\"0.446\">outta</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.31%); opacity: 0.81\" title=\"0.317\">hand</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.69%); opacity: 0.82\" title=\"0.598\">mane</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["720\n","Real Class: ['Toxic']\n","Text uncleaned tweet: honestyhour middle school hoe use call mandingo warrior\n","ELI5 Predicted Class:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=Toxic\n","    \n","</b>\n","\n","    \n","    (probability <b>0.999</b>, score <b>6.881</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +7.849\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 95.38%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.968\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"background-color: hsl(120, 100.00%, 94.45%); opacity: 0.81\" title=\"0.461\">honestyhour</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.29%); opacity: 0.80\" title=\"0.165\">middle</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.02%); opacity: 0.84\" title=\"1.548\">school</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"7.732\">hoe</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.78%); opacity: 0.86\" title=\"2.320\">use</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.71%); opacity: 0.85\" title=\"1.777\">call</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.18%); opacity: 0.81\" title=\"0.376\">mandingo</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.53%); opacity: 0.81\" title=\"0.338\">warrior</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["16200\n","Real Class: ['Non Toxic']\n","Text uncleaned tweet: someone murder police investigate spouse first tell everything need know abo\n","ELI5 Predicted Class:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=Non Toxic\n","    \n","</b>\n","\n","    \n","    (probability <b>0.985</b>, score <b>-4.166</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +3.308\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 92.22%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +0.858\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"opacity: 0.80\">someone </span><span style=\"background-color: hsl(120, 100.00%, 74.65%); opacity: 0.90\" title=\"0.854\">murder</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.75%); opacity: 0.81\" title=\"-0.067\">police</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 70.22%); opacity: 0.93\" title=\"1.074\">investigate</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.74%); opacity: 0.81\" title=\"0.067\">spouse</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.638\">first</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.02%); opacity: 0.81\" title=\"-0.061\">tell</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.90%); opacity: 0.86\" title=\"-0.486\">everything</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.70%); opacity: 0.86\" title=\"0.495\">need</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.00%); opacity: 0.80\" title=\"0.040\">know</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.20%); opacity: 0.87\" title=\"-0.600\">abo</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["54751\n","Real Class: ['Non Toxic']\n","Text uncleaned tweet: months already break fiorelli handbag break\n","ELI5 Predicted Class:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=Non Toxic\n","    \n","</b>\n","\n","    \n","    (probability <b>1.000</b>, score <b>-10.303</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +9.751\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 97.32%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +0.552\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"background-color: hsl(120, 100.00%, 64.08%); opacity: 0.97\" title=\"1.681\">months</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 70.74%); opacity: 0.93\" title=\"1.254\">already</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.960\">break</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 70.60%); opacity: 0.93\" title=\"1.263\">fiorelli</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 64.82%); opacity: 0.97\" title=\"1.632\">handbag</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.960\">break</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["41425\n","Real Class: ['Non Toxic']\n","Text uncleaned tweet: father day daddy heaven real one thats alwayz stand kid matter happy father day love\n","ELI5 Predicted Class:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=Non Toxic\n","    \n","</b>\n","\n","    \n","    (probability <b>1.000</b>, score <b>-11.398</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +10.852\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 97.53%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +0.546\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"background-color: hsl(120, 100.00%, 72.04%); opacity: 0.92\" title=\"0.883\">father</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.472\">day</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.77%); opacity: 0.89\" title=\"0.677\">daddy</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.95%); opacity: 0.92\" title=\"0.886\">heaven</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.41%); opacity: 0.81\" title=\"0.047\">real</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.35%); opacity: 0.82\" title=\"0.165\">one</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.60%); opacity: 0.89\" title=\"-0.643\">thats</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.66%); opacity: 0.85\" title=\"0.340\">alwayz</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.23%); opacity: 0.89\" title=\"0.658\">stand</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 69.13%); opacity: 0.94\" title=\"1.016\">kid</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.42%); opacity: 0.86\" title=\"0.455\">matter</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 70.21%); opacity: 0.93\" title=\"0.966\">happy</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.04%); opacity: 0.92\" title=\"0.883\">father</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.472\">day</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.19%); opacity: 0.91\" title=\"0.787\">love</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["39356\n","Real Class: ['Non Toxic']\n","Text uncleaned tweet: otd last kind die dusky seaside sparrow become extinct\n","ELI5 Predicted Class:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=Non Toxic\n","    \n","</b>\n","\n","    \n","    (probability <b>0.974</b>, score <b>-3.610</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +2.715\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 90.80%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +0.895\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"background-color: hsl(120, 100.00%, 81.67%); opacity: 0.87\" title=\"0.325\">otd</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.53%); opacity: 0.86\" title=\"0.279\">last</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.992\">kind</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 65.37%); opacity: 0.96\" title=\"0.807\">die</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.82%); opacity: 0.84\" title=\"-0.203\">dusky</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 68.59%); opacity: 0.94\" title=\"-0.702\">seaside</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.21%); opacity: 0.83\" title=\"-0.173\">sparrow</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.78%); opacity: 0.82\" title=\"0.086\">become</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.12%); opacity: 0.86\" title=\"-0.314\">extinct</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["55912\n","Real Class: ['Non Toxic']\n","Text uncleaned tweet: family time love family life nuclear kid parent parent positivity\n","ELI5 Predicted Class:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=Non Toxic\n","    \n","</b>\n","\n","    \n","    (probability <b>1.000</b>, score <b>-13.817</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +13.301\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 97.94%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +0.516\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"background-color: hsl(120, 100.00%, 61.62%); opacity: 0.99\" title=\"1.470\">family</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 65.61%); opacity: 0.96\" title=\"1.256\">time</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 63.74%); opacity: 0.97\" title=\"1.355\">love</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 61.62%); opacity: 0.99\" title=\"1.470\">family</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 64.52%); opacity: 0.97\" title=\"1.314\">life</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.90%); opacity: 0.91\" title=\"0.894\">nuclear</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 65.49%); opacity: 0.96\" title=\"1.263\">kid</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.50%); opacity: 1.00\" title=\"1.531\">parent</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.559\">parent</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 64.80%); opacity: 0.97\" title=\"1.299\">positivity</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["2250\n","Real Class: ['Toxic']\n","Text uncleaned tweet: bitch hot do take flight\n","ELI5 Predicted Class:\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <style>\n","    table.eli5-weights tr:hover {\n","        filter: brightness(85%);\n","    }\n","</style>\n","\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","        \n","\n","    \n","\n","        \n","\n","        \n","    \n","        \n","        \n","    \n","        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n","            <b>\n","    \n","        y=Toxic\n","    \n","</b>\n","\n","    \n","    (probability <b>0.961</b>, score <b>3.214</b>)\n","\n","top features\n","        </p>\n","    \n","    <table class=\"eli5-weights\"\n","           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n","        <thead>\n","        <tr style=\"border: none;\">\n","            \n","                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n","                    Contribution<sup>?</sup>\n","                </th>\n","            \n","            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n","            \n","        </tr>\n","        </thead>\n","        <tbody>\n","        \n","            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        +3.717\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        Highlighted in text (sum)\n","    </td>\n","    \n","</tr>\n","        \n","        \n","\n","        \n","        \n","            <tr style=\"background-color: hsl(0, 100.00%, 95.07%); border: none;\">\n","    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n","        -0.503\n","    </td>\n","    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n","        &lt;BIAS&gt;\n","    </td>\n","    \n","</tr>\n","        \n","\n","        </tbody>\n","    </table>\n","\n","    \n","\n","\n","\n","    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n","        <span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"7.768\">bitch</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.09%); opacity: 0.80\" title=\"0.101\">hot</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.54%); opacity: 0.82\" title=\"-0.845\">take</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.01%); opacity: 0.82\" title=\"-0.778\">flight</span>\n","    </p>\n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","    \n","\n","\n","\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"ky1XxIxA7qN4","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}